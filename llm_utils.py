"""
–ú–æ–¥—É–ª—å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å LLM
"""
import logging
from typing import Optional, List
from openai import OpenAI
from config import OPENAI_API_KEY

logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–ª–∏–µ–Ω—Ç OpenAI
client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None

def load_system_prompt() -> str:
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞ –∏–∑ Context.txt"""
    try:
        with open("Context.txt", "r", encoding="utf-8") as f:
            base_prompt = f.read().strip()
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –≥–æ–≤–æ—Ä–∏—Ç—å —Ç–æ–ª—å–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
        return base_prompt + "\n\n–í–ê–ñ–ù–û: –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π –∞–Ω–≥–ª–∏–π—Å–∫–∏–µ —Å–ª–æ–≤–∞ –∏–ª–∏ —Ñ—Ä–∞–∑—ã –≤ –æ—Ç–≤–µ—Ç–∞—Ö."
    except Exception as e:
        logger.error(f"Failed to load system prompt: {e}")
        return "–¢—ã ‚Äî –ö–∞—Ç—è –°–æ–±—É—Ç—ã–ª—å–Ω–∏—Ü–∞: –∂–∏–≤–∞—è –¥–µ–≤—É—à–∫–∞, –¥—Ä—É–∂–µ–ª—é–±–Ω–∞—è, –Ω–µ–º–Ω–æ–≥–æ —Ñ–ª–∏—Ä—Ç—É–µ—à—å, –ª—é–±–∏—à—å –ø–æ—à—É—Ç–∏—Ç—å –∏ –≤—ã–ø–∏—Ç—å. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."

SYSTEM_PROMPT = load_system_prompt()

def llm_reply(text_in: str, user_tg_id: int, chat_id: int, recent_messages: List[dict]) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —á–µ—Ä–µ–∑ LLM"""
    if client is None:
        return "–£ –º–µ–Ω—è —Å–µ–π—á–∞—Å –ø—Ä–æ–±–ª–µ–º—ã —Å –æ—Ç–≤–µ—Ç–æ–º. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ! üòÖ"
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ
        from database import get_user_name, get_user_age, get_user_preferences
        from db_utils import get_user_gender
        
        user_name = get_user_name(user_tg_id) or "–¥—Ä—É–≥"
        user_age = get_user_age(user_tg_id)
        user_gender = get_user_gender(user_tg_id) or "–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω"
        user_preferences = get_user_preferences(user_tg_id)
        
        # –°—Ç—Ä–æ–∏–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
        context_messages = []
        for msg in reversed(recent_messages[-6:]):  # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 6 —Å–æ–æ–±—â–µ–Ω–∏–π
            context_messages.append({
                "role": msg["role"],
                "content": msg["content"]
            })
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        messages = [{"role": "system", "content": SYSTEM_PROMPT}]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ (–ë–ï–ó –í–û–ó–†–ê–°–¢–ê)
        user_info = f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_name}"
        if user_gender != "–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω":
            user_info += f", –ø–æ–ª: {user_gender}"
        if user_preferences:
            user_info += f", –ª—é–±–∏–º—ã–π –Ω–∞–ø–∏—Ç–æ–∫: {user_preferences}"
        
        messages.append({"role": "system", "content": user_info})
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ–æ–±—â–µ–Ω–∏–π
        messages.extend(context_messages)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        messages.append({"role": "user", "content": text_in})
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –∫ LLM
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            max_tokens=200,
            temperature=0.8
        )
        
        response_text = resp.choices[0].message.content.strip()
        
        # –õ–æ–≥–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç LLM –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
        logger.info(f"LLM raw response for user {user_tg_id}: '{response_text}'")
        
        return response_text
        
    except Exception as e:
        logger.exception(f"LLM error for user {user_tg_id}: {e}")
        return "–£ –º–µ–Ω—è —Å–µ–π—á–∞—Å –ø—Ä–æ–±–ª–µ–º—ã —Å –æ—Ç–≤–µ—Ç–æ–º. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ! üòÖ"

def generate_quick_message_llm(first_name: str, preferences: Optional[str], user_tg_id: int) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ LLM –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞"""
    if client is None:
        return f"–ü—Ä–∏–≤–µ—Ç, {first_name}! –ö–∞–∫ –¥–µ–ª–∞? üòâ"
    
    try:
        # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM (–ë–ï–ó –í–û–ó–†–ê–°–¢–ê)
        prompt = f"""–¢—ã ‚Äî –ö–∞—Ç—è –°–æ–±—É—Ç—ã–ª—å–Ω–∏—Ü–∞. –ù–∞–ø–∏—à–∏ –∫–æ—Ä–æ—Ç–∫–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {first_name} –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –¥–∏–∞–ª–æ–≥–∞.

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
- –û–±—Ä–∞—Ç–∏—Å—å –ø–æ –∏–º–µ–Ω–∏ {first_name}
- –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–π –∏ –Ω–µ–º–Ω–æ–≥–æ —Ñ–ª–∏—Ä—Ç—É—é—â–µ–π
- –ù–∞–º–µ–∫–Ω–∏ –Ω–∞ –≤—ã–ø–∏–≤–∫—É –∏–ª–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—É—é –±–µ—Å–µ–¥—É
- –ë—É–¥—å –¥–µ—Ä–∑–∫–æ–π –∏ –∑–∞–º–∞–Ω—á–∏–≤–æ–π
- –ú–∞–∫—Å–∏–º—É–º 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
- –î–æ–±–∞–≤—å —ç–º–æ–¥–∑–∏
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è —Ç–∏–ø–∞ "–ü—Ä–∏–≤–µ—Ç" - —ç—Ç–æ —Å–µ—Ä–µ–¥–∏–Ω–∞ –¥–∏–∞–ª–æ–≥–∞
- –ù–ï —É–ø–æ–º–∏–Ω–∞–π –≤–æ–∑—Ä–∞—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ç–æ—Å—Ç–∞—Ö –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö"""

        if preferences:
            prompt += f"\n- –£—á—Ç–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è: {preferences}"

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=100,
            temperature=0.8
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        logger.error(f"Error generating quick message: {e}")
        return f"–ü—Ä–∏–≤–µ—Ç, {first_name}! –ö–∞–∫ –¥–µ–ª–∞? üòâ"

def generate_auto_message_llm(first_name: str, preferences: Optional[str], user_tg_id: int) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è —á–µ—Ä–µ–∑ LLM"""
    if client is None:
        return f"–ü—Ä–∏–≤–µ—Ç, {first_name}! –°–æ—Å–∫—É—á–∏–ª—Å—è? üòâ"
    
    try:
        # –°—Ç—Ä–æ–∏–º –ø—Ä–æ–º–ø—Ç –¥–ª—è LLM (–ë–ï–ó –í–û–ó–†–ê–°–¢–ê)
        prompt = f"""–¢—ã ‚Äî –ö–∞—Ç—è –°–æ–±—É—Ç—ã–ª—å–Ω–∏—Ü–∞. –ù–∞–ø–∏—à–∏ –∑–∞–º–∞–Ω—á–∏–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é {first_name} —á—Ç–æ–±—ã –≤–µ—Ä–Ω—É—Ç—å –µ–≥–æ –≤ –¥–∏–∞–ª–æ–≥.

–¢–†–ï–ë–û–í–ê–ù–ò–Ø:
- –û–±—Ä–∞—Ç–∏—Å—å –ø–æ –∏–º–µ–Ω–∏ {first_name}
- –ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω–æ–π –∏ —Ñ–ª–∏—Ä—Ç—É—é—â–µ–π
- –ù–∞–º–µ–∫–Ω–∏ –Ω–∞ –≤—ã–ø–∏–≤–∫—É –∏–ª–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—É—é –±–µ—Å–µ–¥—É
- –ë—É–¥—å –¥–µ—Ä–∑–∫–æ–π –∏ –∑–∞–º–∞–Ω—á–∏–≤–æ–π
- –ú–∞–∫—Å–∏–º—É–º 2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
- –î–æ–±–∞–≤—å —ç–º–æ–¥–∑–∏
- –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è —Ç–∏–ø–∞ "–ü—Ä–∏–≤–µ—Ç" - —ç—Ç–æ —Å–µ—Ä–µ–¥–∏–Ω–∞ –¥–∏–∞–ª–æ–≥–∞
- –ù–ï —É–ø–æ–º–∏–Ω–∞–π –≤–æ–∑—Ä–∞—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ç–æ—Å—Ç–∞—Ö –∏–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö"""

        if preferences:
            prompt += f"\n- –£—á—Ç–∏ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è: {preferences}"

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=100,
            temperature=0.8
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        logger.error(f"Error generating auto message: {e}")
        return f"–ü—Ä–∏–≤–µ—Ç, {first_name}! –°–æ—Å–∫—É—á–∏–ª—Å—è? üòâ" 