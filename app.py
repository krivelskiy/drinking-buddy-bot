import os
import logging
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes
from openai import OpenAI

# –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# OpenAI –∫–ª–∏–µ–Ω—Ç
client = OpenAI(api_key=OPENAI_API_KEY)

# Telegram –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
application = Application.builder().token(BOT_TOKEN).build()

# –§—Ä–∞–∑–∞ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
FALLBACK_PHRASE = "–ù—É —á—Ç–æ, –¥—Ä—É–∂–∏—â–µ, –¥–∞–≤–∞–π –≤—ã–ø—å–µ–º –∑–∞ –∑–¥–æ—Ä–æ–≤—å–µ! ü•Ç"


# /start
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –Ø —Ç–≤–æ–π —Å–æ–±—É—Ç—ã–ª—å–Ω–∏–∫ ü§ù –ù–∞–ø–∏—à–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å –∏–ª–∏ –ø–æ–ø—Ä–æ—Å–∏ —Ç–æ—Å—Ç —á–µ—Ä–µ–∑ /toast")


# /toast
async def toast(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã –≤–µ—Å—ë–ª—ã–π —Å–æ–±—É—Ç—ã–ª—å–Ω–∏–∫, –ø—Ä–∏–¥—É–º—ã–≤–∞–µ—à—å –∫–æ—Ä–æ—Ç–∫–∏–µ —Ç–æ—Å—Ç—ã."},
                {"role": "user", "content": "–ü—Ä–∏–¥—É–º–∞–π —Ç–æ—Å—Ç."}
            ]
        )
        toast_text = response.choices[0].message.content if response and response.choices else None
        await update.message.reply_text(toast_text or FALLBACK_PHRASE)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –≤ /toast: {e}")
        await update.message.reply_text(FALLBACK_PHRASE)


# –û—Ç–≤–µ—Ç –Ω–∞ –ª—é–±—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
async def chat(update: Update, context: ContextTypes.DEFAULT_TYPE):
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–¢—ã —Å–æ–±—É—Ç—ã–ª—å–Ω–∏–∫: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—à—å —Ä–∞–∑–≥–æ–≤–æ—Ä, —à—É—Ç–∏—à—å, –ø—Ä–µ–¥–ª–∞–≥–∞–µ—à—å —Ç–æ—Å—Ç—ã."},
                {"role": "user", "content": update.message.text}
            ]
        )
        reply = response.choices[0].message.content if response and response.choices else None
        await update.message.reply_text(reply or FALLBACK_PHRASE)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ OpenAI –≤ chat: {e}")
        await update.message.reply_text(FALLBACK_PHRASE)


# –†–æ—É—Ç—ã
application.add_handler(CommandHandler("start", start))
application.add_handler(CommandHandler("toast", toast))
application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, chat))


# –î–ª—è Render
import asyncio
from fastapi import FastAPI
from telegram.ext import Updater

web_app = FastAPI()

@web_app.get("/")
async def root():
    return {"status": "ok"}

async def run_bot():
    await application.initialize()
    await application.start()
    await application.updater.start_webhook(
        listen="0.0.0.0",
        port=int(os.getenv("PORT", 10000)),
        url_path=BOT_TOKEN,
        webhook_url=f"https://{os.getenv('RENDER_EXTERNAL_HOSTNAME')}/{BOT_TOKEN}"
    )

asyncio.get_event_loop().create_task(run_bot())

app = web_app
